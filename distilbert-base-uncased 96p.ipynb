{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aadc93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pds, numpy as np, tensorflow as tf\n",
    "import nltk, itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae21e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensures the dataframe is 50% legit 50% phish:\n",
    "def get5050(df):\n",
    "    nPhish = len(df[df['label']==1])\n",
    "    nLegit = len(df[df['label']==0])\n",
    "    \n",
    "    nMin = min(nPhish, nLegit)\n",
    "    #select the nMin phish-rows\n",
    "    sPhish = df[df['label']==1].sample(n=nMin)\n",
    "    #select the nMin legit-rows\n",
    "    sLegit = df[df['label']==0].sample(n=nMin)\n",
    "    \n",
    "    if(len(sPhish)!=len(sLegit)):\n",
    "        print(\"Error laoding 50/50 dataset\")\n",
    "        \n",
    "    return sLegit.append(sPhish,ignore_index=True)\n",
    "\n",
    "\n",
    "def proc_urls(df, splitter):    \n",
    "    if(not isinstance(splitter,nltk.tokenize.regexp.RegexpTokenizer)):\n",
    "        raise TypeError(\"splitter of proc_url must be nltk RegexpTokenizer\")\n",
    "    \n",
    "    if(procURL==False):\n",
    "        return df\n",
    "    \n",
    "    newUrls = []\n",
    "    for url in df[\"url\"]:\n",
    "        url = str(url).lower()\n",
    "\n",
    "        url.encode('utf-8', 'ignore').decode()\n",
    "        urlSplit = [clean.strip() for clean in splitter.tokenize(url) if(clean.strip()!=\"\")]\n",
    "    \n",
    "        newUrls += \" \".join(urlSplit)\n",
    "    df[\"url\"] = newUrls\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db3e7d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names, cTitle='Confusion Matrix'):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    NOTE: Modified from output of scikit learn!  \n",
    "    EXPECTS: [[tp, fp],[fn,tn]]\n",
    "    \n",
    "    Args:\n",
    "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "    class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "  \n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(cTitle)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    #Normalize the confusion matrix.\n",
    "    #cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    colm = np.array([[\"white\",\"black\"],[\"black\",\"white\"]])\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=colm[i,j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.xlabel('Truth')\n",
    "  \n",
    "    return figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41ae6e2",
   "metadata": {},
   "source": [
    "## Setup tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e273163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import DataCollatorWithPadding,TFAutoModelForSequenceClassification, RobertaTokenizerFast, TFRobertaForSequenceClassification, TFTrainer, TFTrainingArguments, DistilBertTokenizer, TFDistilBertModel\n",
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad48ab",
   "metadata": {},
   "source": [
    "##  Let's create/load a CSV into a dataset object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f850fe26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24310, 60775)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6078, 15195)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#load the csv:\n",
    "dfTrain = pds.read_csv(\"../../data/compiled/allTrain.csv\", index_col = 0)\n",
    "dfTest = pds.read_csv(\"../../data/compiled/allTest.csv\", index_col = 0)\n",
    "\n",
    "splitter = nltk.RegexpTokenizer(\"\\d+|[a-z]+|\\W\")\n",
    "procURL=False\n",
    "\n",
    "dfLegit = dfTrain[dfTrain[\"label\"]==0]\n",
    "dfPhish = dfTrain[dfTrain[\"label\"]==1]\n",
    "\n",
    "\n",
    "dfTrainFixed = get5050(dfTrain)\n",
    "dfTestFixed = get5050(dfTest)\n",
    "\n",
    "dfTrainFixed = proc_urls(dfTrainFixed,splitter)\n",
    "dfTestFixed = proc_urls(dfTestFixed,splitter)\n",
    "\n",
    "display((len(dfTrainFixed), len(dfTrain)))\n",
    "display((len(dfTestFixed), len(dfTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a38f204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>luckywebsoft.com/hardcore/amateur-takes-multip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>asilikyl.ru/263223163.php</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>mabilo.com/303458-adeep-izinkan.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>www.stjude.org/about-st-jude/stories/making-a-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>funstock.co/trough-bathtub/trough-bathtub-hors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24305</th>\n",
       "      <td>1</td>\n",
       "      <td>firebasestorage.googleapis.com/v0/b/wbimail.ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24306</th>\n",
       "      <td>1</td>\n",
       "      <td>base.etagy.net/login.php</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24307</th>\n",
       "      <td>1</td>\n",
       "      <td>www.tpm.servlces.runescape.com-er.ru/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24308</th>\n",
       "      <td>1</td>\n",
       "      <td>clck.ru/PJHdG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24309</th>\n",
       "      <td>1</td>\n",
       "      <td>www.csytravels.in/well-known/pki-validation/fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24310 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                                url\n",
       "0          0  luckywebsoft.com/hardcore/amateur-takes-multip...\n",
       "1          0                          asilikyl.ru/263223163.php\n",
       "2          0                mabilo.com/303458-adeep-izinkan.htm\n",
       "3          0  www.stjude.org/about-st-jude/stories/making-a-...\n",
       "4          0  funstock.co/trough-bathtub/trough-bathtub-hors...\n",
       "...      ...                                                ...\n",
       "24305      1  firebasestorage.googleapis.com/v0/b/wbimail.ap...\n",
       "24306      1                           base.etagy.net/login.php\n",
       "24307      1              www.tpm.servlces.runescape.com-er.ru/\n",
       "24308      1                                      clck.ru/PJHdG\n",
       "24309      1  www.csytravels.in/well-known/pki-validation/fo...\n",
       "\n",
       "[24310 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrainFixed\n",
    "#tf.data.Dataset.from_tensor_slices(dict(dfTrainFixed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07fea967",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataset = Dataset.from_pandas(dfTrainFixed)\n",
    "TestDataset = Dataset.from_pandas(dfTestFixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c367efd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['label', 'url'],\n",
       "     num_rows: 24310\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['label', 'url'],\n",
       "     num_rows: 6078\n",
       " }))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainDataset,TestDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d650d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10d7e276097481f8e64bc7c91eba0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3122a510ac774a6ea2258980d1f5f18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"url\"], truncation=True)\n",
    "\n",
    "tokenized_TrainDatasets = TrainDataset.map(tokenize_function, batched=True)\n",
    "tokenized_TestDatasets = TestDataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30253e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'input_ids', 'label', 'url'],\n",
       "    num_rows: 24310\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_TrainDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23e6b713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function TensorflowDatasetMixin.to_tf_dataset.<locals>.fetch_function at 0x7ff88c146f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TensorflowDatasetMixin.to_tf_dataset.<locals>.fetch_function at 0x7ff88c146f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TensorflowDatasetMixin.to_tf_dataset.<locals>.ensure_shapes at 0x7ff85bf204c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TensorflowDatasetMixin.to_tf_dataset.<locals>.ensure_shapes at 0x7ff85bf204c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TensorflowDatasetMixin.to_tf_dataset.<locals>.split_features_and_labels at 0x7ff81821bdc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TensorflowDatasetMixin.to_tf_dataset.<locals>.split_features_and_labels at 0x7ff81821bdc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TensorflowDatasetMixin.to_tf_dataset.<locals>.rename_label_col at 0x7ff8180d7820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TensorflowDatasetMixin.to_tf_dataset.<locals>.rename_label_col at 0x7ff8180d7820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TensorflowDatasetMixin.to_tf_dataset.<locals>.fetch_function at 0x7ff8181d51f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TensorflowDatasetMixin.to_tf_dataset.<locals>.fetch_function at 0x7ff8181d51f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TensorflowDatasetMixin.to_tf_dataset.<locals>.ensure_shapes at 0x7ff8181d50d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TensorflowDatasetMixin.to_tf_dataset.<locals>.ensure_shapes at 0x7ff8181d50d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TensorflowDatasetMixin.to_tf_dataset.<locals>.split_features_and_labels at 0x7ff818174700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TensorflowDatasetMixin.to_tf_dataset.<locals>.split_features_and_labels at 0x7ff818174700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function TensorflowDatasetMixin.to_tf_dataset.<locals>.rename_label_col at 0x7ff818174a60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TensorflowDatasetMixin.to_tf_dataset.<locals>.rename_label_col at 0x7ff818174a60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "\n",
    "tf_train_dataset = tokenized_TrainDatasets.to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\"],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=128,\n",
    ")\n",
    "\n",
    "tf_validation_dataset = tokenized_TestDatasets.to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\"],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14c97d0",
   "metadata": {},
   "source": [
    "## Fine tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7ec7bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'vocab_layer_norm', 'activation_13', 'vocab_projector']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_39', 'pre_classifier', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36ab0648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "189/189 [==============================] - 3334s 18s/step - loss: 0.0948 - accuracy: 0.9671 - val_loss: 0.0985 - val_accuracy: 0.9664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff65c6af4f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "batch_size = 128\n",
    "num_epochs = 2\n",
    "# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied\n",
    "# by the total number of epochs\n",
    "num_train_steps = len(tf_train_dataset) * num_epochs\n",
    "lr_scheduler = PolynomialDecay(\n",
    "    initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps\n",
    ")\n",
    "\n",
    "opt = Adam(learning_rate=lr_scheduler)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer=opt, loss=loss, metrics=[\"accuracy\"])\n",
    "model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00f9acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(tf_validation_dataset)[\"logits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebca9d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_preds = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d190f74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6078, 6078)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = tokenized_TestDatasets[\"label\"]\n",
    "len(class_preds),len(tokenized_TestDatasets[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25388069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names, cTitle='Confusion Matrix'):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    NOTE: Modified from output of scikit learn!  \n",
    "    EXPECTS: [[tp, fp],[fn,tn]]\n",
    "    \n",
    "    Args:\n",
    "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "    class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "  \n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(cTitle)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    #Normalize the confusion matrix.\n",
    "    #cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    colm = np.array([[\"white\",\"black\"],[\"black\",\"white\"]])\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=colm[i,j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.xlabel('Truth')\n",
    "  \n",
    "    return figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817e4b7e",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc556c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bal Accuracy: 96.644%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(results, class_preds).ravel()\n",
    "traccuracy = (tp + tn)/(tn + tp + fn + fp)\n",
    "traccuracyB = ((tp/(tp+fn) + tn/(fp+tn))*0.5)\n",
    "print(\"Training Bal Accuracy: {:.3f}%\".format(traccuracyB*100.))\n",
    "cmatrix = np.array([[tp, fp],[fn, tn]])\n",
    "disp = plot_confusion_matrix(cmatrix, ['Phish','Legit'], cTitle='Training Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4892195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(preds, results):\n",
    "        confusion_matrix = np.zeros((2,2))\n",
    "        for i in range(len(results)):\n",
    "            confusion_matrix[preds[i]][results[i]]+=1\n",
    "        # precision=TP/(TP+FP) recall f1 accuracy\n",
    "        precision = 0 if confusion_matrix[1][1]+confusion_matrix[1][0]==0 else confusion_matrix[1][1]/(confusion_matrix[1][1]+confusion_matrix[1][0])\n",
    "        recall = 0 if confusion_matrix[1][1]+confusion_matrix[0][1]==0 else confusion_matrix[1][1]/(confusion_matrix[1][1]+confusion_matrix[0][1])\n",
    "        f1 = 0.0 if precision+recall==0 else 2*precision*recall/(precision+recall)\n",
    "        accuracy = (confusion_matrix[0][0]+confusion_matrix[1][1])/np.sum(confusion_matrix)\n",
    "        print(\"The precision is: {0}\\nThe recall is: {1}\\nThe f1 is: {2}\\nThe accuracy is: {3}\"\n",
    "              .format(precision,recall,f1,accuracy))\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f09dd61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision is: 0.9701492537313433\n",
      "The recall is: 0.9624876604146101\n",
      "The f1 is: 0.9663032705649157\n",
      "The accuracy is: 0.9664363277393879\n"
     ]
    }
   ],
   "source": [
    "evaluate(class_preds,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb5598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e252bd19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
