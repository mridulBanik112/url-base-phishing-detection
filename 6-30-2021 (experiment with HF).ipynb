{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pds, numpy as np, tensorflow as tf\n",
    "import nltk, itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensures the dataframe is 50% legit 50% phish:\n",
    "def get5050(df):\n",
    "    nPhish = len(df[df['label']==1])\n",
    "    nLegit = len(df[df['label']==0])\n",
    "    \n",
    "    nMin = min(nPhish, nLegit)\n",
    "    #select the nMin phish-rows\n",
    "    sPhish = df[df['label']==1].sample(n=nMin)\n",
    "    #select the nMin legit-rows\n",
    "    sLegit = df[df['label']==0].sample(n=nMin)\n",
    "    \n",
    "    if(len(sPhish)!=len(sLegit)):\n",
    "        print(\"Error laoding 50/50 dataset\")\n",
    "        \n",
    "    return sLegit.append(sPhish,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_urls(df, splitter):    \n",
    "    if(not isinstance(splitter,nltk.tokenize.regexp.RegexpTokenizer)):\n",
    "        raise TypeError(\"splitter of proc_url must be nltk RegexpTokenizer\")\n",
    "    \n",
    "    if(procURL==False):\n",
    "        return df\n",
    "    \n",
    "    newUrls = []\n",
    "    for url in df[\"url\"]:\n",
    "        url = str(url).lower()\n",
    "\n",
    "        url.encode('utf-8', 'ignore').decode()\n",
    "        urlSplit = [clean.strip() for clean in splitter.tokenize(url) if(clean.strip()!=\"\")]\n",
    "    \n",
    "        newUrls += \" \".join(urlSplit)\n",
    "    df[\"url\"] = newUrls\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newUrls = []\n",
    "#demourl = \"komix.fandom.com/el/wiki/%CE%95%CF%80%CE%B9%CE%B8%CE%B5%CF%89%CF%81%CE%B7%CF%84%CE%AE%CF%82_%CE%9F%27%CE%A7%CE%AC%CF%81%CE%B1?diff=87300&oldid=32428\"\n",
    "#demourl = str(demourl).lower()\n",
    "#demourl.encode('utf-8', 'ignore').decode()\n",
    "#demosplitter = nltk.RegexpTokenizer(\"\\d+|[a-z]+|\\W\")\n",
    "#urlSplit = [clean.strip() for clean in demosplitter.tokenize(demourl) if(clean.strip()!=\"\")]\n",
    "#newUrls += \" \".join(urlSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names, cTitle='Confusion Matrix'):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    NOTE: Modified from output of scikit learn!  \n",
    "    EXPECTS: [[tp, fp],[fn,tn]]\n",
    "    \n",
    "    Args:\n",
    "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "    class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "  \n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(cTitle)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    #Normalize the confusion matrix.\n",
    "    #cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    colm = np.array([[\"white\",\"black\"],[\"black\",\"white\"]])\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=colm[i,j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.xlabel('Truth')\n",
    "  \n",
    "    return figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets create our own pipeline for fine tuning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the setup for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertTokenizer, ElectraTokenizerFast, RobertaTokenizerFast, TFElectraForSequenceClassification, TFBertForSequenceClassification, TFRobertaForSequenceClassification, TFTrainer, TFTrainingArguments\n",
    "\n",
    "checkpoint = \"bert-base-uncased\" #this is the checkpoint (pretrained model) we are using for the example.\n",
    "tokenizer = BertTokenizer.from_pretrained(checkpoint) #setup the tokenizer. We need to pass it the checkpoint because hf models need a specific mapping of word-ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create/load a CSV into a dataset object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#load the csv:\n",
    "dfTrain = pds.read_csv(\"../proj/data/compiled/allTrainOrigin.csv\", index_col = 0) # small set 413\n",
    "dfTest = pds.read_csv(\"../proj/data/compiled/allTestOrigin.csv\", index_col = 0) # small set 75\n",
    "dfLegit = dfTrain[dfTrain[\"label\"]==0] # small 200\n",
    "dfPhish = dfTrain[dfTrain[\"label\"]==1] # small 213\n",
    "dfTrainFixed = get5050(dfTrain) # ensure phishing and legit data ratio 1:1\n",
    "dfTestFixed = get5050(dfTest)\n",
    "#dfTrainFixed[\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24310, 60775)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6078, 15195)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "splitter = nltk.RegexpTokenizer(\"\\d+|[a-z]+|\\W\")\n",
    "procURL = False\n",
    "dfTrainFixed = proc_urls(dfTrainFixed,splitter)\n",
    "dfTestFixed = proc_urls(dfTestFixed,splitter)\n",
    "\n",
    "display((len(dfTrainFixed), len(dfTrain)))\n",
    "display((len(dfTestFixed), len(dfTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>www.dinnercheque.nl/dinnercheque-restaurants/z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>gogreydog.com/careers/human-resources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>suresuta.jp/archives/83870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>speakerdeck.com/brenoferreira/remote-work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>www.yourwdwstore.net/Disney-Countdown-To-Chris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1</td>\n",
       "      <td>my-halifax-uk.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1</td>\n",
       "      <td>theuniversityoftomorrow.org/images/gallery/use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1</td>\n",
       "      <td>www.lightlink.com.cn/sites/default/files/2017-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1</td>\n",
       "      <td>battlepubgmobile.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1</td>\n",
       "      <td>www.windowfrance.com/secure/secure/0bd58c69f42...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                                url\n",
       "0        0  www.dinnercheque.nl/dinnercheque-restaurants/z...\n",
       "1        0              gogreydog.com/careers/human-resources\n",
       "2        0                         suresuta.jp/archives/83870\n",
       "3        0          speakerdeck.com/brenoferreira/remote-work\n",
       "4        0  www.yourwdwstore.net/Disney-Countdown-To-Chris...\n",
       "..     ...                                                ...\n",
       "395      1                                 my-halifax-uk.com/\n",
       "396      1  theuniversityoftomorrow.org/images/gallery/use...\n",
       "397      1  www.lightlink.com.cn/sites/default/files/2017-...\n",
       "398      1                              battlepubgmobile.com/\n",
       "399      1  www.windowfrance.com/secure/secure/0bd58c69f42...\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrainFixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(dfTrainFixed[\"url\"])\n",
    "y = list(dfTrainFixed[\"label\"])\n",
    "\n",
    "#X_train, X_val, y_train, y_val\n",
    "xTR, xVA, yTR, yVA = train_test_split(x,y, shuffle=True, test_size=0.2) # shuffle all train and test data, 20% be test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tEncoding = tokenizer(xTR, truncation=True, padding=True) # tokenizer -> inputs, including token_ids and attention mask\n",
    "vEncoding = tokenizer(xVA, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19448"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tEncoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-04 21:45:04.919747: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "trainDS = tf.data.Dataset.from_tensor_slices((dict(tEncoding),yTR))\n",
    "valDS = tf.data.Dataset.from_tensor_slices((dict(vEncoding),yVA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ({input_ids: (512,), token_type_ids: (512,), attention_mask: (512,)}, ()), types: ({input_ids: tf.int32, token_type_ids: tf.int32, attention_mask: tf.int32}, tf.int32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Lets do some Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support( \\\n",
    "                           labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#OUTPUT_DIR=\"/s/fir/e/nobackup/Fresh-Phish/transformer_exps/progs/Trained Models\"\n",
    "OUTPUT_DIR=\"../proj/progs/TrainedModels\"\n",
    "training_args = TFTrainingArguments(output_dir=OUTPUT_DIR,            # output directory\n",
    "            evaluation_strategy=\"steps\",      # evaluation strategy\n",
    "            num_train_epochs=3,               # total number of training epochs\n",
    "            per_device_train_batch_size=16,  # batch size per device during training\n",
    "            per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "            per_gpu_train_batch_size=16,\n",
    "            per_gpu_eval_batch_size=16,\n",
    "            warmup_steps=10000,  # number of warmup steps for learning rate scheduler\n",
    "            weight_decay=0.01,   # strength of weight decay\n",
    "            learning_rate=8.e-5, # Adam learning rate\n",
    "            adam_epsilon=1.e-6)  # Adam epsilon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.distribute_lib._CurrentDistributionContext at 0x14d517ed0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.strategy.scope()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/proj/lib/python3.7/site-packages/transformers/trainer_tf.py:114: FutureWarning: The class `TFTrainer` is deprecated and will be removed in version 5 of Transformers. We recommend using native Keras instead, by calling methods like `fit()` and `predict()` directly on the model object. Detailed examples of the Keras style can be found in our examples at https://github.com/huggingface/transformers/tree/master/examples/tensorflow\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "with training_args.strategy.scope():\n",
    "    model = TFBertForSequenceClassification.from_pretrained(\n",
    "            \"bert-base-uncased\")\n",
    "    \n",
    "trainer = TFTrainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=trainDS,               # training dataset\n",
    "    eval_dataset=valDS,                  # evaluation dataset\n",
    "    compute_metrics=compute_metrics      # evaluation metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "2021-11-04 21:46:49.728917: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_4\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "input: \"Placeholder/_2\"\n",
      "input: \"Placeholder/_3\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 512\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 512\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 512\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2021-11-04 21:46:49.857000: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2021-11-04 21:46:49.860206: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "trainer.train() # train.fit\n",
    "stop = time.time()\n",
    "print(\"Fine-Tuning Time: {:.2f}\".format(stop-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "2021-10-27 10:51:31.439565: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_4\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "input: \"Placeholder/_2\"\n",
      "input: \"Placeholder/_3\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 410\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 410\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 410\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "2021-10-27 10:51:31.614822: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4375\n"
     ]
    }
   ],
   "source": [
    "model_result = trainer.evaluate()\n",
    "print(\"Accuracy: {}\".format(model_result['eval_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Looks good. Lets predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTE = list(dfTestFixed[\"url\"])\n",
    "yTE = list(dfTestFixed[\"label\"])\n",
    "#create the test dataset:\n",
    "\n",
    "testEncoding = tokenizer(xTE,truncation=True, padding=True)\n",
    "testDS=tf.data.Dataset.from_tensor_slices((dict(testEncoding), yTE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "2021-10-27 11:12:24.902033: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_4\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "input: \"Placeholder/_2\"\n",
      "input: \"Placeholder/_3\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 409\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 409\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 409\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "2021-10-27 11:12:24.951244: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bal Accuracy: 50.000%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_train = trainer.predict(testDS)\n",
    "trlabels = pred_train.label_ids\n",
    "trpreds = pred_train.predictions.argmax(-1)\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(trlabels, trpreds).ravel()\n",
    "traccuracy = (tp + tn)/(tn + tp + fn + fp)\n",
    "traccuracyB = ((tp/(tp+fn) + tn/(fp+tn))*0.5)\n",
    "print(\"Training Bal Accuracy: {:.3f}%\".format(traccuracyB*100.))\n",
    "cmatrix = np.array([[tp, fp],[fn, tn]])\n",
    "disp = plot_confusion_matrix(cmatrix, ['Phish','Legit'], cTitle='Training Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
